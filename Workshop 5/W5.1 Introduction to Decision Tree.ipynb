{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"W5.1 Introduction to Decision Tree","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPtkxu2z2yXI4+rOZ3wkJNZ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6aq9AcPXDZLJ","colab_type":"text"},"source":["# Prepare Environment\n","Thr first section is to import necesssary modules for this Colab notebook."]},{"cell_type":"code","metadata":{"id":"1pCwUYEMgxQN","colab_type":"code","colab":{}},"source":["# Load libraries\n","import numpy as np\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fYCg2PgZDfwK","colab_type":"text"},"source":["# Create a simple dataset\n","We first start by creating a simple, small fruit dataset, which can be used to train a decision tree.\n","Here, we will create the dataset using DataFrame from the Pandas library."]},{"cell_type":"code","metadata":{"id":"1j4__QrAhIxx","colab_type":"code","colab":{}},"source":["df = pd.DataFrame({\n","    'color': ['green','yellow','red','red','yellow'],\n","    'diameter': [3,3,1,1,3],\n","    'label': ['apple','apple','grape','grape','lemon']  # 0: Apple, 1:Grape, 2: Lemon\n","})\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Zj4VtiTEh-v","colab_type":"text"},"source":["As you can see from the output above, we have create the fruit dataset consisting of three columns: `color`, `diameter` and `label`.\n","\n","The first two columns (i.e., `color` and `diameter`) are the **features** or the characteristics of each fruit, while the last column (i.e., `label`) are the **label** or the answer that we expect the decision tree to know when it accepts the color and diameter values."]},{"cell_type":"markdown","metadata":{"id":"oxUFoEdsFprL","colab_type":"text"},"source":["# Categorical Columns\n","\n","It should be emphasize that most of the ML algorithms expect numerical features (e.g., integer and floating-point numbers) as input.\n","\n","However, there are two columns that are NOT numerical, which are `color` and `label`. We need to convert such columns into numerical ones. \n","\n","For categorical features (i.e., `color`), we commonly convert them into what is called **one-hot** format. We **DO NOT** use a number such as 0, 1, 2 as it brings in a natural order for different categories.\n","\n","```\n","color=green  --> 0 --> [1, 0, 0]\n","color=red    --> 1 --> [0, 1, 0]\n","color=yellow --> 2 --> [0, 0, 1]\n","```\n","\n","It should be noted that it **DOES NOT** matter which number you assign for `red`, `green` and `yellow` as long as they are consistent.\n","\n","The following code shows an example of how to use the `get_dummies` function to convert from the categorical feature into the one-hot format."]},{"cell_type":"code","metadata":{"id":"TruXIjX3I79l","colab_type":"code","colab":{}},"source":["pd.get_dummies(df['color'], prefix='color')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nocEQdM3I-jY","colab_type":"text"},"source":["We append such one-hot features into the dataframe."]},{"cell_type":"code","metadata":{"id":"qe1KfdH6O_hT","colab_type":"code","colab":{}},"source":["color_code_df = pd.get_dummies(df['color'], prefix='color')\n","df = pd.concat([df, color_code_df], axis=1)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G0NHBnFbJVeZ","colab_type":"text"},"source":["Next, we will convert the `label` column into integer numbers (e.g., 0, 1 and 2). Again, it **DOES NOT** matter which number you assign as long as you are consistent for the task.\n","\n","Here we will use `LabelEncoder` from scikit-learn to convert from string to class numbers, and then create a new column, named `label_code`, to keep the output."]},{"cell_type":"code","metadata":{"id":"DQAnvI-KPcPv","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import LabelEncoder\n","\n","label_enc = LabelEncoder()\n","df['label_code'] = label_enc.fit_transform(df['label'])\n","print(label_enc.classes_)\n","\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LzPMaWV2Ljwy","colab_type":"text"},"source":["Once we have successfully convert categorical columns into numerical ones. We will drop the categorical columns from the dataframe."]},{"cell_type":"code","metadata":{"id":"_iquxiqDik3c","colab_type":"code","colab":{}},"source":["data_df = df.drop(columns=['color','label'])\n","data_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Y6u2wBoLwja","colab_type":"text"},"source":["# Prepare a Training Set\n","\n","As mentioned in the slide that a training set consists of pairs of data (or features) and labels, we will extract features and labels from the dataframe.\n","\n","We typically use `X` for features and `y` for labels."]},{"cell_type":"code","metadata":{"id":"rux1qXksh7l_","colab_type":"code","colab":{}},"source":["# Prepare the training set\n","X = data_df.drop(columns=['label_code']).values\n","y = data_df['label_code'].values\n","print(X)\n","print(y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z6-8nQPHNWeJ","colab_type":"text"},"source":["The following is the code to get the name of each feature column and store in a `feature_names` variable."]},{"cell_type":"code","metadata":{"id":"qXrhe6yTGP7B","colab_type":"code","colab":{}},"source":["feature_names = data_df.drop(columns=['label_code']).columns.values\n","feature_names"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x_CSYLnRNip7","colab_type":"text"},"source":["# Train a Decision Tree\n","\n","In this section, we will create and train a decision tree model using [scikit-learn](https://scikit-learn.org/), which is one of the most popular Python package for machine learning.\n","\n","The module that we will use is [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."]},{"cell_type":"code","metadata":{"id":"IYhd6_Nlhi26","colab_type":"code","colab":{}},"source":["from sklearn.tree import DecisionTreeClassifier\n","\n","# Create Decision Tree classifer object\n","clf = DecisionTreeClassifier(random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Je-eVO3mOpdC","colab_type":"text"},"source":["To train the model, we simply call `fit` function with the training set that we have prepared: `X` and `y`."]},{"cell_type":"code","metadata":{"id":"xmsYqtizhxnf","colab_type":"code","colab":{}},"source":["# Train Decision Tree Classifer\n","clf = clf.fit(X,y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K2-nwr9rOz3p","colab_type":"text"},"source":["# Prediction\n","\n","In this section, we will use the *trained* decision tree to predict the types of fruit based on the `color` and `diameter`.\n","\n","To make predictions, we call `predict` function with the input features. Let's have a try on the training set."]},{"cell_type":"code","metadata":{"id":"fTt223Ynhxv-","colab_type":"code","colab":{}},"source":["# Predict the response for test dataset\n","y_pred = clf.predict(X)\n","print(y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GvibILIfPbr1","colab_type":"text"},"source":["It can be seen that the predictions are still the class number. If we want to know the name of each class, we can use the same `LabelEncoder` to inverse the predicted class from numbers back to string."]},{"cell_type":"code","metadata":{"id":"YCesU52Mj4Ww","colab_type":"code","colab":{}},"source":["print(label_enc.inverse_transform(y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PJV-QA3DQgHy","colab_type":"text"},"source":["One of common metrics that we can use to evaluate the performance of the model is **accuracy**, which is the closeness of a measured value to a standard or known value."]},{"cell_type":"code","metadata":{"id":"OWithFLRQ26l","colab_type":"code","colab":{}},"source":["np.mean(y_pred == y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qsX6WVFvRAl6","colab_type":"text"},"source":["# Visualize the Trained Decision Tree\n","\n","It is also helpful to understand the criteria that the model uses to make predictions. For the decision tree, we can use `export_graphviz` module to visualize the tree."]},{"cell_type":"code","metadata":{"id":"4fDhw-nDjeLL","colab_type":"code","colab":{}},"source":["from sklearn.tree import export_graphviz\n","from subprocess import call\n","import matplotlib.pyplot as plt\n","\n","# Export the decision tree\n","export_graphviz(\n","    clf,                             # the trained decision tree here\n","    feature_names=feature_names,     # the list of feature names here\n","    class_names=label_enc.classes_,  # the list of labels here\n","    out_file='tree.dot',\n","    rounded=True, proportion=False, precision=2, filled=True)\n","\n","# Convert to png\n","call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n","\n","# Display in python\n","plt.figure(figsize=(10,12))\n","plt.imshow(plt.imread('tree.png'))\n","plt.axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9IDOiV00Rt4k","colab_type":"text"},"source":["We can also see which are the most importance features for predicting the type of the fruit based on the `color` and the `diameter`.\n","\n","Here we can use the attribute `feature_importances_` from the trained model `clf`."]},{"cell_type":"code","metadata":{"id":"NXo_4aEqlWiM","colab_type":"code","colab":{}},"source":["for i in range(len(feature_names)):\n","    print(f'{feature_names[i]}: {clf.feature_importances_[i]}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bqpo-nS8RckP","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}